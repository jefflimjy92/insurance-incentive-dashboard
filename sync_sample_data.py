"""
ì—°ì†í˜• ì‹œìƒ ë¡œì»¬ ë°ì´í„° ë™ê¸°í™” ìŠ¤í¬ë¦½íŠ¸
Google ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ìµœì‹  ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ sample_data í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤.
"""

import pandas as pd
import os
from data_loader import load_contracts_from_url, load_rules_from_url, load_consecutive_rules

def sync_data():
    spreadsheet_url = "https://docs.google.com/spreadsheets/d/1W0eVca5rbpjXoiw65DaVkIY8793KRkoMH8oi8BHp-ow/edit"
    base_dir = os.path.dirname(os.path.abspath(__file__))
    sample_dir = os.path.join(base_dir, 'sample_data')
    
    if not os.path.exists(sample_dir):
        os.makedirs(sample_dir)
        
    print(f"ğŸš€ ë™ê¸°í™” ì‹œì‘: {spreadsheet_url}")
    
    try:
        # 1. ê³„ì•½ ë°ì´í„° ë™ê¸°í™”
        print("ğŸ“¥ ê³„ì•½ ë°ì´í„° ë¡œë“œ ì¤‘...")
        contracts_df = load_contracts_from_url(spreadsheet_url, "RAW_ê³„ì•½")
        contracts_path = os.path.join(sample_dir, 'ê³„ì•½ë°ì´í„°.csv')
        contracts_df.to_csv(contracts_path, index=False)
        print(f"âœ… ê³„ì•½ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {len(contracts_df)}ê±´")
        
        # 2. ì‹œìƒ ê·œì¹™ ë™ê¸°í™” (KB, ì‚¼ì„± í•©ë³¸)
        print("ğŸ“¥ ì‹œìƒ ê·œì¹™ ë¡œë“œ ì¤‘...")
        rules_sheets = ["KB", "ì‚¼ì„±"]
        rules_dfs = []
        for sheet in rules_sheets:
            try:
                df = load_rules_from_url(spreadsheet_url, sheet)
                if 'íšŒì‚¬' not in df.columns:
                    df['íšŒì‚¬'] = sheet
                rules_dfs.append(df)
                print(f"  - {sheet} ì‹œíŠ¸ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ")
            except Exception as e:
                print(f"  âš ï¸ {sheet} ì‹œíŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        if rules_dfs:
            combined_rules = pd.concat(rules_dfs, ignore_index=True)
            rules_path = os.path.join(sample_dir, 'ì‹œìƒê·œì¹™.csv')
            combined_rules.to_csv(rules_path, index=False)
            print(f"âœ… ì‹œìƒ ê·œì¹™ ì €ì¥ ì™„ë£Œ: {len(combined_rules)}ê°œ")
            
        # 3. ì—°ì†í˜• ì‹œìƒ ê·œì¹™ ë™ê¸°í™”
        print("ğŸ“¥ ì—°ì†í˜• ì‹œìƒ ê·œì¹™ ë¡œë“œ ì¤‘...")
        # 'ì‚¼ì„±' ì‹œíŠ¸ì— ì—°ì†í˜• ê·œì¹™ì´ í¬í•¨ë˜ì–´ ìˆìŒ
        try:
             from data_loader import load_public_sheet
             con_df = load_public_sheet(spreadsheet_url, "ì‚¼ì„±")
             
             # ì—°ì†í˜• í•„í„°ë§ (ìœ í˜• == 'ì—°ì†í˜•')
             if 'ìœ í˜•' in con_df.columns:
                 con_df = con_df[con_df['ìœ í˜•'] == 'ì—°ì†í˜•'].copy()
             
             # ì»¬ëŸ¼ëª… ë³€í™˜
             mapping = {
                 'ì œíœ´ì‚¬': 'íšŒì‚¬',
                 'ë³´í—˜ì‚¬': 'íšŒì‚¬',
                 'ìµœì¢…ì‹œìƒëª…': 'ì‹œìƒëª…'
             }
             con_df = con_df.rename(columns={k: v for k, v in mapping.items() if k in con_df.columns})
             
             # ìˆ«ì ì»¬ëŸ¼ ë³€í™˜
             numeric_cols = ['êµ¬ê°„ë²ˆí˜¸', 'ëª©í‘œì‹¤ì ', 'ì´ì „êµ¬ê°„ì¡°ê±´', 'ë³´ìƒê¸ˆì•¡']
             for col in numeric_cols:
                 if col in con_df.columns:
                     con_df[col] = con_df[col].astype(str).str.replace(',', '', regex=False)
                     con_df[col] = pd.to_numeric(con_df[col], errors='coerce').fillna(0)
             
             if 'ì‹œì‘ì¼' in con_df.columns:
                 con_df['ì‹œì‘ì¼'] = pd.to_datetime(con_df['ì‹œì‘ì¼'], errors='coerce')
             if 'ì¢…ë£Œì¼' in con_df.columns:
                 con_df['ì¢…ë£Œì¼'] = pd.to_datetime(con_df['ì¢…ë£Œì¼'], errors='coerce')
                 
             con_path = os.path.join(sample_dir, 'ì—°ì†í˜•ì‹œìƒê·œì¹™.csv')
             con_df.to_csv(con_path, index=False)
             print(f"âœ… ì—°ì†í˜• ì‹œìƒ ê·œì¹™ ì €ì¥ ì™„ë£Œ: {len(con_df)}ê°œ")
        except Exception as e:
             print(f"  âš ï¸ ì—°ì†í˜• ì‹œìƒ ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨: {e}")

        print("\nâœ¨ ëª¨ë“  ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœë¡œ ë™ê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"\nâŒ ë™ê¸°í™” ë„ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    sync_data()
